%
% File eacl2017.tex
%
%% Based on the style files for ACL-2016
%% Based on the style files for ACL-2015, with some improvements
%%  taken from the NAACL-2016 style
%% Based on the style files for ACL-2014, which were, in turn,
%% Based on the style files for ACL-2013, which were, in turn,
%% Based on the style files for ACL-2012, which were, in turn,
%% based on the style files for ACL-2011, which were, in turn, 
%% based on the style files for ACL-2010, which were, in turn, 
%% based on the style files for ACL-IJCNLP-2009, which were, in turn,
%% based on the style files for EACL-2009 and IJCNLP-2008...

%% Based on the style files for EACL 2006 by 
%%e.agirre@ehu.es or Sergi.Balari@uab.es
%% and that of ACL 08 by Joakim Nivre and Noah Smith

\documentclass[11pt]{article}
\usepackage{eacl2017}
\usepackage{times}
\usepackage{url}
\usepackage{latexsym}

\eaclfinalcopy % Uncomment this line for the final submission
%\def\eaclpaperid{***} %  Enter the acl Paper ID here

%\setlength\titlebox{5cm}
% You can expand the titlebox if you need extra space
% to show all the authors. Please do not make the titlebox
% smaller than 5cm (the original size); we will check this
% in the camera-ready version and ask you to change it back.

\newcommand\BibTeX{B{\sc ib}\TeX}

\title{OpenNMT: Open-Source Toolkit for Neural Machine Translation}

\author{Yoon Kim, Guillaume Klein, Jean Senellart, Alexander M. Rush ... }

\date{}

\begin{document}
\maketitle
\begin{abstract}

  We describe an open-source toolkit for neural machine translation
  that supports research development of sequence-to-sequence models.
  The system is prioritizes simplicity, modularity, and efficiency to
  make it reasonable for researchers to experiment with variants of
  neural machine translation that explore different feature
  representations, model architectures, and source (multi)-modalities,
  while maintaining competitive performance and tractable training
  requirements. The toolkit consists of modeling and decoding support,
  as well as detailed pedagogical documentation about the underlying
  methodologies.

\end{abstract}

\section{Introduction}


\begin{itemize}
\item Description of current state of NMT
\item Difference with other NMT
\item Description of open-source nmt systems. Several research systems, but there is a not a ... 
\end{itemize}


Motivation of building a new system.

Prioritized factor 

\begin{itemize}
\item Training efficiency
\item System Modularity
\item Support for alternative representations
\item Industrial decoding.
\end{itemize}


\section{Background: Neural Machine Translation}

\begin{itemize}
\item One column describing the technical details
\end{itemize}


\section{Implementation}

\subsection{Modularity}

\begin{itemize}
\item Separate encoder/decoder 
\item Arbitrary input/output representations (features, images)
\end{itemize}

\subsection{Optimizations}

\begin{itemize}
\item Shared memory
\item C-Decoder 
\end{itemize}

\subsection{Advanced Features}

\section{User Studies}

\paragraph{Feature-Based Inputs}

\paragraph{Knowledge Distillation}

\paragraph{Im2Latex}

\section{Experimental Results}

\begin{table}
  \centering
  
  \caption{Performance Results}
\end{table}


\begin{table}
  \centering
  
  \caption{Speed Results. Multi-GPU, distillation, c decoder}
\end{table}




\bibliography{writeup}
\bibliographystyle{eacl2017}


\end{document}
